{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization an syncronization with Nimble API\n",
    "*By Dmytro Mendzhul, Aug 2023.*\n",
    "\n",
    "This is a Jupiter notebook for testing approaches when solving test task from Nimble.<br> \n",
    "It contains only database initaalization and syncronization approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start PostgreSQL [OPTIONAL]\n",
    "Skip this step if PostgreSQL is already running on port 5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    ". ~/.bashrc\n",
    "docker-compose -f ../deploy/docker-compose-db.yml --project-directory . up --build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `contact` table\n",
    "### Define helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg # Alternatively, SQLAlchemy can be used, but the task has condition not to use ORM\n",
    "from yarl import URL\n",
    "\n",
    "def run_sql_command(sql: str, db_url: URL) -> None:\n",
    "    \"\"\"Runs a PSQL command.\n",
    "\n",
    "    Args:\n",
    "        sql (str): The SQL command to run.\n",
    "        db_url (URL): database URL.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    with psycopg.connect(conninfo=str(db_url)) as conn, \\\n",
    "        conn.cursor() as cursor:\n",
    "        try:\n",
    "            cursor.execute(sql)\n",
    "            conn.commit()\n",
    "        finally:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SKIP] (for convenience) drop `contact` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimblesync.settings import settings\n",
    "\n",
    "# Remove 'contact' table\n",
    "try:\n",
    "    run_sql_command('DROP TABLE IF EXISTS contact', settings.db_url)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `contact` table:\n",
    "\n",
    "Some columns explanation:\n",
    "- `id` - autoincremented\n",
    "- `external_id` - for Nimble API resource identifiers, indexed\n",
    "- `removed` - value '`t`' means external contact is no longer exist on API, default `f`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimblesync.settings import settings\n",
    "\n",
    "create_contact_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS contact (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    external_id VARCHAR ( 50 ) UNIQUE,\n",
    "    first_name VARCHAR ( 255 ),\n",
    "    last_name VARCHAR ( 255 ),\n",
    "    email VARCHAR ( 255 ),\n",
    "    removed BOOLEAN DEFAULT FALSE NOT NULL,\n",
    "    textsearchable_index_col tsvector\n",
    "        GENERATED ALWAYS AS (to_tsvector('english',\n",
    "            coalesce(first_name, '') || ' ' || \n",
    "            coalesce(last_name, '') || ' ' || \n",
    "            coalesce(email, '')\n",
    "        )) STORED\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Run\n",
    "run_sql_command(create_contact_table_sql, settings.db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import initial data from CSV\n",
    "### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_DATA_FILE_PATH = '../seed/Nimble Contacts - Sheet1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Observe initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first name      last name                               Email\n",
      "0       Oleg         Mishyn               mystylename@gmail.com\n",
      "1        Ken  Underwood III  kenneth.underwood@yahoofinance.com\n",
      "2      kitty          akbar                      asd1@gmail.com\n",
      "3      Craig       Jamieson           craig@salesresultsllc.com\n",
      "4    Francis          Hoang                    fqjunk@gmail.com\n",
      "...\n",
      "TOTAL: 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_initial = pd.read_csv(SEED_DATA_FILE_PATH)\n",
    "print(df_initial.head())\n",
    "print(f'...\\nTOTAL: {len(df_initial)}')\n",
    "del(df_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed initial data to database:\n",
    "\n",
    "Note that seed CSV file can contain large amount of data.\n",
    "Therefore, to perform import efficiently, PostgreSQL 'COPY' command is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported seed data into 'contact' table.\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from nimblesync.settings import settings\n",
    "\n",
    "def seed_contacts(csv_path: str, check_if_empty: bool = True, verbose: bool = False) -> None:\n",
    "\n",
    "    with open(csv_path, \"r\") as file, \\\n",
    "        psycopg.connect(conninfo=str(settings.db_url)) as conn, \\\n",
    "        conn.cursor() as cursor:\n",
    "        try:            \n",
    "            run_import = True\n",
    "\n",
    "            if check_if_empty:\n",
    "                cursor.execute('SELECT COUNT(*) FROM contact')\n",
    "                count = cursor.fetchone()[0]\n",
    "                if count > 0:\n",
    "                    run_import = False\n",
    "                    if verbose:\n",
    "                        print(f'Found {count} records in \\'contact\\' table. Skipping seed.')\n",
    "            \n",
    "            if run_import:\n",
    "                with cursor.copy(\"\"\"\n",
    "                            COPY contact(\n",
    "                                first_name,\n",
    "                                last_name,\n",
    "                                email)\n",
    "                            FROM stdin (format csv, delimiter ',', quote '\\\"')\"\"\") as copy:\n",
    "                    copy.write(file.read())\n",
    "\n",
    "                conn.commit()\n",
    "                if verbose:\n",
    "                    print(f'Successfully imported seed data into \\'contact\\' table.')\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "seed_contacts(SEED_DATA_FILE_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Nimble API\n",
    "### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimblesync.settings import settings\n",
    "\n",
    "NIMBLE_CONTACTS_IDS_ENDPOINT = settings.nimble_contacts_ids_endpoint\n",
    "NIMBLE_CONTACTS_ENDPOINT = settings.nimble_contacts_endpoint\n",
    "NIMBLE_TOKEN = settings.nimble_token\n",
    "NIMBLE_HEADERS = { 'Authorization': 'Bearer ' + NIMBLE_TOKEN }\n",
    "SUCCESS_STATUS_CODE = 200\n",
    "BATCH_SIZE = 10 # can be increased, but for test purpose let it be small\n",
    "DEFAULT_BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import requests\n",
    "\n",
    "def get_params(page: int, fields: [str] = None) -> dict[str, any]:\n",
    "    \"\"\"Generate parameters for a query.\n",
    "\n",
    "    Args:\n",
    "        page (int): The page number.\n",
    "        fields ([str]): Fields to return.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, any]:A dictionary of parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {'page': page}\n",
    "    \n",
    "    if BATCH_SIZE != DEFAULT_BATCH_SIZE:\n",
    "        params['per_page'] = BATCH_SIZE\n",
    "\n",
    "    if (fields is not None):\n",
    "        params['fields'] = ','.join(fields)\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_field(resource: dict[str, any], field: str) -> str:\n",
    "    \"\"\"Gets the field value of contact resource\n",
    "\n",
    "    Args:\n",
    "        resource (dict[str, any]): The contact from Nimble API.\n",
    "        field (str): The field name.\n",
    "\n",
    "    Returns:\n",
    "        str: The value of the field.\n",
    "    \"\"\"\n",
    "    return next(iter(resource['fields'].get(field, [])), {}).get('value')\n",
    "\n",
    "# [OPTIONAL]\n",
    "def load_all_contact_ids(verbose: bool = False) -> set[str]:\n",
    "    \"\"\"Loads all contact IDs from the Nimble API.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool, optional): Whether to print status messages. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        set[str]: A set of contact IDs\n",
    "    \"\"\"\n",
    "    \n",
    "    page = 0\n",
    "    contact_ids = set()\n",
    "\n",
    "    while True:\n",
    "        page += 1\n",
    "    \n",
    "        params = get_params(page)\n",
    "        response_API = requests.get(NIMBLE_CONTACTS_IDS_ENDPOINT, headers=NIMBLE_HEADERS, params=params)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'GET ids (page={page}): status={response_API.status_code}')\n",
    "\n",
    "        if (response_API.status_code != SUCCESS_STATUS_CODE):\n",
    "            break\n",
    "\n",
    "        page_json = response_API.json()\n",
    "    \n",
    "        page_contact_ids = page_json['resources']\n",
    "        contact_ids.update(page_contact_ids)\n",
    "\n",
    "        pages = page_json['meta']['pages']\n",
    "    \n",
    "        if page >= pages:\n",
    "            break\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'loaded {len(contact_ids)} unique IDs.')\n",
    "\n",
    "    return contact_ids\n",
    "\n",
    "# [OPTIONAL]\n",
    "def load_all_contacts(verbose: bool = False) -> dict[str, any]:\n",
    "    \"\"\"Loads all contacts from the Nimble API.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool, optional): Whether to print status messages. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, any]: A dictioraty of contacts.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = 0\n",
    "    contacts = {}\n",
    "\n",
    "    while True:\n",
    "        page += 1\n",
    "    \n",
    "        params = get_params(page, ['first name','last name','email'])\n",
    "        response_API = requests.get(NIMBLE_CONTACTS_ENDPOINT, headers=NIMBLE_HEADERS, params=params)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'GET contacts (page={page}): status={response_API.status_code}')\n",
    "\n",
    "        if (response_API.status_code != SUCCESS_STATUS_CODE):\n",
    "            break\n",
    "\n",
    "        page_json = response_API.json()\n",
    "        \n",
    "        contacts.update({x['id']: {\n",
    "            'external_id':x['id'],\n",
    "            'first_name':get_field(x, 'first name'),\n",
    "            'last_name':get_field(x, 'last name'),\n",
    "            'email':get_field(x, 'email')\n",
    "        } for x in page_json['resources']})\n",
    "\n",
    "        pages = page_json['meta']['pages']\n",
    "    \n",
    "        if page >= pages:\n",
    "            break\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'loaded {len(contacts)} contacts.')\n",
    "    \n",
    "    return contacts\n",
    "\n",
    "\n",
    "def load_paginated_contacts(verbose: bool = False) -> Iterator[list[tuple[str, ...]]]:\n",
    "    \"\"\"Loads all contacts from the Nimble API by pages.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool, optional): Whether to print status messages. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, any]: A dictioraty of contacts.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = 0\n",
    "    total = 0\n",
    "\n",
    "    while True:\n",
    "        page += 1\n",
    "    \n",
    "        params = get_params(page, ['first name','last name','email'])\n",
    "        response_API = requests.get(NIMBLE_CONTACTS_ENDPOINT, headers=NIMBLE_HEADERS, params=params)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'GET contacts (page={page}): status={response_API.status_code}')\n",
    "\n",
    "        if (response_API.status_code != SUCCESS_STATUS_CODE):\n",
    "            break\n",
    "\n",
    "        page_json = response_API.json()\n",
    "        \n",
    "        chunk = [(\n",
    "            str(x['id']),\n",
    "            get_field(x, 'first name'),\n",
    "            get_field(x, 'last name'),\n",
    "            get_field(x, 'email')\n",
    "        ) for x in page_json['resources']]\n",
    "\n",
    "        yield chunk\n",
    "\n",
    "        total += len(chunk)\n",
    "        pages = page_json['meta']['pages']\n",
    "    \n",
    "        if page >= pages:\n",
    "            break\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'loaded {len(total)} contacts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Load all contact IDs from Nimble API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET ids (page=1): status=200\n",
      "GET ids (page=2): status=200\n",
      "GET ids (page=3): status=200\n",
      "GET ids (page=4): status=200\n",
      "loaded 34 unique IDs.\n",
      "Example: 64ca0fa3d1d39db980b9d418\n"
     ]
    }
   ],
   "source": [
    "nimble_contact_ids = load_all_contact_ids(verbose=True)\n",
    "print('Example:', nimble_contact_ids.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Load all contacts from Nimble API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET contacts (page=1): status=200\n",
      "GET contacts (page=2): status=200\n",
      "GET contacts (page=3): status=200\n",
      "GET contacts (page=4): status=200\n",
      "loaded 34 contacts.\n",
      "Example: {'external_id': '64ca0fa7d1d39db980b9d458', 'first_name': 'Randy', 'last_name': 'Smith', 'email': 'smith.r@samsung.com'}\n"
     ]
    }
   ],
   "source": [
    "nimble_contacts = load_all_contacts(verbose=True)\n",
    "print(\"Example:\", list(nimble_contacts.values())[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Read external contacts stored in db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 34\n",
      "Example: {'id': 45, 'external_id': '64ca0fa7d1d39db980b9d458', 'first name': 'Randy', 'last name': 'Smith', 'email': 'smith.r@samsung.com', 'removed': False}\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from yarl import URL\n",
    "from nimblesync.settings import settings\n",
    "\n",
    "def get_external_contacts_from_db(db_url: URL) -> dict[str, dict[str, any]]:\n",
    "    \"\"\" Read all external contacts (with external_id) from database\n",
    "\n",
    "    Args:\n",
    "        db_url (URL): database URL.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[str, any]]: Dictionary of contacts keyed by external_id\n",
    "    \"\"\"\n",
    "\n",
    "    query_sql = '''\n",
    "    SELECT id, external_id, first_name, last_name, email, removed\n",
    "    FROM contact\n",
    "    WHERE external_id IS NOT NULL;\n",
    "    '''\n",
    "    contacts = {}\n",
    "\n",
    "    with psycopg.connect(conninfo=str(db_url)) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query_sql)\n",
    "            entities = cursor.fetchall()\n",
    "            contacts = {str(x[1]): {\n",
    "                'id':x[0],\n",
    "                'external_id':x[1],\n",
    "                'first name':x[2],\n",
    "                'last name':x[3],\n",
    "                'email':x[4],\n",
    "                'removed':x[5]\n",
    "            } for x in entities}\n",
    "            \n",
    "    return contacts\n",
    "\n",
    "# Run\n",
    "current_contacts = get_external_contacts_from_db(settings.db_url)\n",
    "\n",
    "print(\"Total:\", len(current_contacts))\n",
    "print(\"Example:\", list(current_contacts.values())[-1] if current_contacts else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update database from Nimble API\n",
    "Now let's copy data to temp table and perform UPSERT and 'REMOVE' (with status) operatons\n",
    "\n",
    "Note that using COPY (bulk insert) is fastest way to populate postgres table.<br> \n",
    "This is psycopg3 implementation, more details here: https://www.psycopg.org/psycopg3/docs/basic/copy.html<br> \n",
    "In psycopg2 it would be cursor.copy_from with buffer: https://hakibenita.com/fast-load-data-python-postgresql<br> \n",
    "Another performance benchmarking here:<br> \n",
    "https://github.com/NaysanSaran/pandas2postgresql/blob/master/notebooks/Psycopg2_Bulk_Insert_Speed_Benchmark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from nimblesync.settings import settings\n",
    "\n",
    "# Load contacts from Nimble API as lists of tuples, page by page:\n",
    "# (this will run slower, due to API response)\n",
    "chunks = load_paginated_contacts()\n",
    "# To use pre-loaded data from bloks above, use instead:\n",
    "# chunks = [[tuple(x.values()) for x in nimble_contacts.values()]]\n",
    "\n",
    "def update_contacts_with_external_data(chunks: Iterator[list[tuple[str, ...]]]) -> None:\n",
    "    \"\"\"Loads contacts page-by-page to temp table, then upserts into 'contact' table and marks missing records as removed\n",
    "\n",
    "    Args:\n",
    "        chunks (Iterator[list[tuple[str, ...]]]): Paginated contact records from Nimble API\n",
    "    \"\"\"\n",
    "\n",
    "    with psycopg.connect(conninfo=str(settings.db_url)) as conn, \\\n",
    "        conn.cursor() as cursor:\n",
    "        try:\n",
    "            # Create temp table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TEMP TABLE tmp_contact(\n",
    "                    external_id VARCHAR ( 50 ),\n",
    "                    first_name VARCHAR ( 255 ),\n",
    "                    last_name VARCHAR ( 255 ),\n",
    "                    email VARCHAR ( 255 ))\n",
    "                    ON COMMIT DROP;\"\"\")\n",
    "            \n",
    "            # Bulk copy to temp table\n",
    "            for chunk in chunks:\n",
    "                with cursor.copy(\"\"\"\n",
    "                    COPY tmp_contact(\n",
    "                        external_id,\n",
    "                        first_name,\n",
    "                        last_name,\n",
    "                        email)\n",
    "                    FROM stdin;\"\"\") as copy:\n",
    "                    for row in chunk:\n",
    "                        copy.write_row(row)\n",
    "        \n",
    "        # Add new records and update existing ones if there are changes\n",
    "        # Also, sets removed=FALSE if a previously deleted record reappears\n",
    "            cursor.execute(\"\"\"\n",
    "            INSERT INTO contact (\n",
    "                external_id,\n",
    "                first_name,\n",
    "                last_name,\n",
    "                email)\n",
    "            SELECT\n",
    "                external_id,\n",
    "                first_name,\n",
    "                last_name,\n",
    "                email\n",
    "            FROM tmp_contact\n",
    "            ON CONFLICT (external_id)  DO UPDATE  SET\n",
    "                first_name=EXCLUDED.first_name,\n",
    "                last_name=EXCLUDED.last_name,\n",
    "                email=EXCLUDED.email,\n",
    "                removed=FALSE\n",
    "            WHERE\n",
    "                contact.first_name != EXCLUDED.first_name OR\n",
    "                contact.last_name != EXCLUDED.last_name OR\n",
    "                contact.email != EXCLUDED.email OR\n",
    "                contact.removed = TRUE;\"\"\")\n",
    "        \n",
    "        # Mark as removed contacts that are no longer returned by the API\n",
    "        # (additional index can improve this update, as shown in Appendix 1)\n",
    "            cursor.execute(\"\"\"\n",
    "            CREATE UNIQUE INDEX tmp_contact_external_id_key ON tmp_contact (external_id);\n",
    "            UPDATE contact c\n",
    "            SET removed = TRUE\n",
    "            WHERE\n",
    "                c.external_id IS NOT NULL AND\n",
    "                NOT EXISTS (\n",
    "                    SELECT FROM tmp_contact t\n",
    "                    WHERE t.external_id = c.external_id\n",
    "                );\"\"\")\n",
    "\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cursor.close()\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "update_contacts_with_external_data(chunks)\n",
    "print('Updated successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 3, 'external_id': None, 'first name': 'Ken', 'last name': 'Underwood III', 'email': 'kenneth.underwood@yahoofinance.com', 'removed': False}\n",
      "{'id': 9, 'external_id': None, 'first name': 'Ken', 'last name': 'Gray', 'email': 'kgray@cc-techgroup.com', 'removed': False}\n",
      "{'id': 45, 'external_id': '64ca0fa7d1d39db980b9d458', 'first name': 'Randy', 'last name': 'Smith', 'email': 'smith.r@samsung.com', 'removed': False}\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "from yarl import URL\n",
    "from nimblesync.settings import settings\n",
    "\n",
    "def search_for_contacts(db_url: URL, search: str, limit: int = 10, offset: int = 0) -> list[dict[str, any]]:\n",
    "    \"\"\" Read all external contacts (with external_id) from database\n",
    "\n",
    "    Args:\n",
    "        db_url (URL): database URL.\n",
    "        search (str): Search text.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[str, any]]: Dictionary of contacts keyed by external_id\n",
    "    \"\"\"\n",
    "\n",
    "    query_sql = '''\n",
    "    SELECT id, external_id, first_name, last_name, email, removed\n",
    "    FROM contact\n",
    "    WHERE textsearchable_index_col @@ to_tsquery(%s)\n",
    "    LIMIT %s OFFSET %s;'''\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    with psycopg.connect(conninfo=str(db_url)) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query_sql, (search, limit, offset))\n",
    "            entities = cursor.fetchall()\n",
    "            res = [{\n",
    "                'id':x[0],\n",
    "                'external_id':x[1],\n",
    "                'first name':x[2],\n",
    "                'last name':x[3],\n",
    "                'email':x[4],\n",
    "                'removed':x[5]\n",
    "            } for x in entities]\n",
    "            \n",
    "    return res\n",
    "\n",
    "# Run\n",
    "found_contacts = search_for_contacts(settings.db_url, 'Ken | Smith')\n",
    "\n",
    "for record in found_contacts:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix 1\n",
    "Query plan comparison with and without additional index on temp table:\n",
    "\n",
    "\n",
    "      nimblesync=# CREATE TABLE tmp2 AS TABLE contact;\n",
    "      SELECT 45\n",
    "      nimblesync=# EXPLAIN UPDATE contact c\n",
    "                  SET removed = TRUE\n",
    "                  WHERE\n",
    "                  c.external_id IS NOT NULL AND\n",
    "                  NOT EXISTS (\n",
    "                        SELECT FROM tmp2 t\n",
    "                        WHERE t.external_id = c.external_id\n",
    "                  );\n",
    "                                    QUERY PLAN                                 \n",
    "      ----------------------------------------------------------------------------\n",
    "      Update on contact c  (cost=10.90..21.45 rows=1 width=1683)\n",
    "      ->  Hash Anti Join  (cost=10.90..21.45 rows=1 width=1683)\n",
    "            Hash Cond: ((c.external_id)::text = (t.external_id)::text)\n",
    "            ->  Seq Scan on contact c  (cost=0.00..10.40 rows=40 width=1676)\n",
    "                  Filter: (external_id IS NOT NULL)\n",
    "            ->  Hash  (cost=10.40..10.40 rows=40 width=124)\n",
    "                  ->  Seq Scan on tmp2 t  (cost=0.00..10.40 rows=40 width=124)\n",
    "      (7 rows)\n",
    "\n",
    "      nimblesync=# CREATE UNIQUE INDEX tmp2_external_id_key ON tmp2 (external_id);\n",
    "      CREATE INDEX\n",
    "      nimblesync=# EXPLAIN UPDATE contact c\n",
    "                  SET removed = TRUE\n",
    "                  WHERE\n",
    "                  c.external_id IS NOT NULL AND\n",
    "                  NOT EXISTS (\n",
    "                        SELECT FROM tmp2 t\n",
    "                        WHERE t.external_id = c.external_id\n",
    "                  );\n",
    "                                    QUERY PLAN                                 \n",
    "      ---------------------------------------------------------------------------\n",
    "      Update on contact c  (cost=2.01..12.56 rows=1 width=1683)\n",
    "      ->  Hash Anti Join  (cost=2.01..12.56 rows=1 width=1683)\n",
    "            Hash Cond: ((c.external_id)::text = (t.external_id)::text)\n",
    "            ->  Seq Scan on contact c  (cost=0.00..10.40 rows=40 width=1676)\n",
    "                  Filter: (external_id IS NOT NULL)\n",
    "            ->  Hash  (cost=1.45..1.45 rows=45 width=124)\n",
    "                  ->  Seq Scan on tmp2 t  (cost=0.00..1.45 rows=45 width=124)\n",
    "      (7 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert this notebook to HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook sync.ipynb to html\n",
      "[NbConvertApp] Writing 342759 bytes to sync.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    ". ~/.bashrc\n",
    "jupyter nbconvert --to html sync.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
